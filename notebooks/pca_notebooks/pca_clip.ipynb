{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91095b-6c23-4a76-aff7-27e10433e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA plot saved to: /home/bboulbarss/pca_plots/clip/text_pca_clip_plot.png\n",
      "Bar plot saved to: /home/bboulbarss/pca_plots/clip/clip_probabilities_bar_plot.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Update font sizes globally\n",
    "plt.rcParams.update({\n",
    "    'font.size': 15,\n",
    "    'axes.titlesize': 17,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 13,\n",
    "    'ytick.labelsize': 13,\n",
    "    'legend.fontsize': 13,\n",
    "    'legend.title_fontsize': 14,\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# -- configurable labels --\n",
    "\n",
    "##### IMAGE 1 #####\n",
    "#labels1 = [\n",
    "#    \"A photo of a cube right of a cone\",\n",
    "#    \"A photo of a cube left of a cone\",\n",
    "#    \"A photo of a cone right of a cube\",\n",
    "#    \"A photo of a cube left of a sphere\",\n",
    "#    \"A photo of a cylinder right of a cone\",]\n",
    "#correct_label1 = \"A photo of a cube right of a cone\"\n",
    "#image_path1 = \"/home/bboulbarss/large_dataset/relational/ood_val/cube_right_cone/cube right cone/CLEVR_rel_000025.png\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "## Image 1 in final_gradcam\n",
    "## Relational\n",
    "#labels = [\n",
    "#    \"A photo of a cylinder left of a cone\",\n",
    "#    \"A photo of a cylinder right of a cone\",\n",
    "#    \"A photo of a cone left of a cylinder\",\n",
    "#    \"A photo of a cube right a cylinder\",\n",
    "#    \"A photo of a sphere right of a cone\",]\n",
    "#correct_label = \"A photo of a cylinder left of a cone\"\n",
    "#image_path = \"/home/bboulbarss/large_dataset/relational/train/cylinder_left_cone/CLEVR_rel_000020.png\"\n",
    "#\n",
    "## Two object\n",
    "#labels = [\n",
    "#    \"A photo of a purple cylinder\",\n",
    "#    \"A photo of a green cylinder\",\n",
    "#    \"A photo of a purple cone\",\n",
    "#    \"A photo of a red sphere\",\n",
    "#    \"A photo of a blue cube\"\n",
    "#]\n",
    "#correct_label = \"A photo of a purple cylinder\"\n",
    "#image_path = \"/home/bboulbarss/large_dataset/relational/train/cylinder_left_cone/CLEVR_rel_000020.png\"\n",
    "\n",
    "################################################################################################\n",
    "# Image 2 in final_gradcam\n",
    "# Relational\n",
    "#labels = [\n",
    "#    \"A photo of a cylinder left of a sphere\",\n",
    "#    \"A photo of a cylinder right of a sphere\",\n",
    "#    \"A photo of a sphere left of a cylinder\",\n",
    "#    \"A photo of a cube right a cone\",\n",
    "#    \"A photo of a sphere right of a cone\",]\n",
    "#correct_label = \"A photo of a cylinder left of a sphere\"\n",
    "#image_path = \"/home/bboulbarss/large_dataset/relational/train/cylinder_left_sphere/CLEVR_rel_000031.png\"\n",
    "#\n",
    "## Two object\n",
    "#labels = [\n",
    "#    \"A photo of a green sphere\",\n",
    "#    \"A photo of a blue sphere\",\n",
    "#    \"A photo of a green cylinder\",\n",
    "#    \"A photo of a red cone\",\n",
    "#    \"A photo of a purple cube\",\n",
    "#]\n",
    "#correct_label = \"A photo of a green sphere\"\n",
    "#image_path = \"/home/bboulbarss/large_dataset/relational/train/cylinder_left_sphere/CLEVR_rel_000031.png\"\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def clip_predict_label(image_path, labels, model, processor):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Process the inputs\n",
    "    inputs = processor(text=labels, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Get model outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract the image-text similarity scores\n",
    "    logits_per_image = outputs.logits_per_image\n",
    "    # Convert logits to probabilities\n",
    "    probs = logits_per_image.softmax(dim=1)\n",
    "\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# Directory to save PCA plot\n",
    "save_dir = '/home/bboulbarss/pca_plots/clip'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "plot_path = os.path.join(save_dir, 'text_pca_clip_plot.png')\n",
    "\n",
    "# -- Load CLIP model and processor --\n",
    "model_name = 'openai/clip-vit-base-patch32'\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "model = model.to(device)\n",
    "model.eval()  # set model to evaluation mode\n",
    "\n",
    "# -- Prepare text inputs and compute embeddings --\n",
    "inputs = processor(text=labels, return_tensors='pt', padding=True)\n",
    "# Move inputs to the same device as the model\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    text_features = model.get_text_features(**inputs)\n",
    "\n",
    "# -- Normalize embeddings for cosine-based analysis --\n",
    "text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "embeddings = text_features.cpu().numpy()\n",
    "\n",
    "# sim_matrix = cosine_similarity(embeddings)\n",
    "# dist_matrix = cosine_distances(embeddings)\n",
    "# print(\"Cosine Similarity Matrix:\")\n",
    "# print(np.round(sim_matrix, 4))\n",
    "# print(\"Cosine Distance Matrix:\")\n",
    "# print(np.round(dist_matrix, 4))\n",
    "\n",
    "# -- PCA projection to 2 dimensions --\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "probabilities = clip_predict_label(\n",
    "    image_path=image_path,\n",
    "    labels=labels,\n",
    "    model=model,\n",
    "    processor=processor    \n",
    ")\n",
    "\n",
    "# -- Plot PCA result --\n",
    "colorblind_colors = sns.color_palette(\"colorblind\")\n",
    "palette = {\"original\": colorblind_colors[2], \"ft\": (1, 0, 0)}\n",
    "\n",
    "# -- Plot PCA result --\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Separate points into \"correct\" and \"others\"\n",
    "correct_indices = [i for i, label in enumerate(labels) if label == correct_label]\n",
    "other_indices = [i for i, label in enumerate(labels) if label != correct_label]\n",
    "\n",
    "# Plot \"correct\" points\n",
    "if correct_indices:\n",
    "    plt.scatter(\n",
    "        embeddings_2d[correct_indices, 0], embeddings_2d[correct_indices, 1],\n",
    "        c=[palette[\"original\"]],  # Color for correct label\n",
    "        s=200,  # Larger circle for correct label\n",
    "        marker='o',  # Circle marker\n",
    "        label=\"Correct Label\"  # Legend entry\n",
    "    )\n",
    "\n",
    "# Plot \"others\" points\n",
    "if other_indices:\n",
    "    plt.scatter(\n",
    "        embeddings_2d[other_indices, 0], embeddings_2d[other_indices, 1],\n",
    "        c=[palette[\"ft\"]],  # Color for other labels\n",
    "        s=100,  # Smaller circle for others\n",
    "        marker='o',  # Circle marker\n",
    "        label=\"Wrong Label\"  # Legend entry\n",
    "    )\n",
    "\n",
    "# Equalize axis scales to avoid distortion\n",
    "plt.axis('equal')\n",
    "\n",
    "# Annotate points with labels, adjusting position to keep within bounds\n",
    "x_range = plt.xlim()\n",
    "y_range = plt.ylim()\n",
    "x_offset = 0.01 * (x_range[1] - x_range[0])\n",
    "y_offset = 0.01 * (y_range[1] - y_range[0])\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        (embeddings_2d[i, 0] + x_offset, embeddings_2d[i, 1] + y_offset),\n",
    "        fontsize=13,\n",
    "        alpha=0.8,\n",
    "        ha='left',\n",
    "        va='bottom',\n",
    "        wrap=True\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"PCA Visualization of CLIP Text Embeddings\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# -- Save and close plot --\n",
    "plt.savefig(plot_path, bbox_inches='tight', dpi=500)\n",
    "plt.close()\n",
    "\n",
    "print(f\"PCA plot saved to: {plot_path}\")\n",
    "\n",
    "# -- Create bar plot for probabilities --\n",
    "# Sort labels and probabilities in descending order\n",
    "probs = probabilities[0]  # assuming shape (1, N)\n",
    "sorted_indices = np.argsort(probs)[::-1]\n",
    "sorted_labels = [labels[i] for i in sorted_indices]\n",
    "sorted_probs = [probs[i] * 100 for i in sorted_indices]  # convert to percentages\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "# Create color list: green for correct_label, red for others\n",
    "colors = ['green' if label == correct_label else 'red' for label in sorted_labels]\n",
    "bars = plt.bar(sorted_labels, sorted_probs, color=colors)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Probability (%)\", rotation=0, labelpad=40)\n",
    "plt.title(\"CLIP Label Probabilities for Image\")\n",
    "\n",
    "# Ticks\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(np.linspace(0, 100, 6))\n",
    "\n",
    "# Add legend\n",
    "legend_handles = [plt.Rectangle((0,0),1,1, color='green'), plt.Rectangle((0,0),1,1, color='red')] if correct_label in sorted_labels else [plt.Rectangle((0,0),1,1, color='red')]\n",
    "legend_labels = ['Correct Label', 'Wrong Labels'] if correct_label in sorted_labels else ['Other Labels']\n",
    "plt.legend(handles=legend_handles, labels=legend_labels, loc='upper right')\n",
    "\n",
    "# Layout and save\n",
    "plt.tight_layout()\n",
    "bar_plot_path = os.path.join(save_dir, 'clip_probabilities_bar_plot.png')\n",
    "plt.savefig(bar_plot_path, bbox_inches='tight', dpi=500)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Bar plot saved to: {bar_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c93d4b-04e4-4d9b-af27-15549eea10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Define base directory and set directories\n",
    "base_dir = \"/home/bboulbarss/large_dataset/relational\"\n",
    "sets = {\n",
    "    \"train\": os.path.join(base_dir, \"train\"),\n",
    "    \"val\": os.path.join(base_dir, \"ood_val\"),\n",
    "    \"test\": os.path.join(base_dir, \"ood_test\"),\n",
    "}\n",
    "\n",
    "# Define markers for each set\n",
    "markers = {\"train\": \"o\", \"val\": \"s\", \"test\": \"^\"}\n",
    "\n",
    "# Function to get image paths based on set and directory structure\n",
    "def get_image_paths(set_name, set_dir):\n",
    "    image_data = []\n",
    "    # Get classes, ignoring dot files\n",
    "    classes = [c for c in os.listdir(set_dir) if not c.startswith('.')]\n",
    "    if set_name == \"train\":\n",
    "        for cls in classes:\n",
    "            cls_dir = os.path.join(set_dir, cls)\n",
    "            # Get images, ignoring dot files\n",
    "            images = [img for img in os.listdir(cls_dir) if not img.startswith('.')]\n",
    "            for img in images:\n",
    "                path = os.path.join(cls_dir, img)\n",
    "                image_data.append((path, cls, set_name))\n",
    "    else:  # val or test\n",
    "        for cls in classes:\n",
    "            cls_dir = os.path.join(set_dir, cls)\n",
    "            # Get the intermediate directory (assume there's only one, ignoring dot files)\n",
    "            intermediate_dirs = [d for d in os.listdir(cls_dir) if not d.startswith('.') and os.path.isdir(os.path.join(cls_dir, d))]\n",
    "            if intermediate_dirs:  # Ensure there's at least one intermediate directory\n",
    "                intermediate_dir = os.path.join(cls_dir, intermediate_dirs[0])\n",
    "                # Get images, ignoring dot files\n",
    "                images = [img for img in os.listdir(intermediate_dir) if not img.startswith('.')]\n",
    "                for img in images:\n",
    "                    path = os.path.join(intermediate_dir, img)\n",
    "                    image_data.append((path, cls, set_name))\n",
    "    return image_data\n",
    "\n",
    "# Collect all image data\n",
    "all_image_data = []\n",
    "for set_name, set_dir in sets.items():\n",
    "    image_data = get_image_paths(set_name, set_dir)\n",
    "    all_image_data.extend(image_data)\n",
    "\n",
    "# Extract image paths, classes, and sets\n",
    "image_paths, classes, sets_list = zip(*all_image_data)\n",
    "\n",
    "# Load images\n",
    "images = [Image.open(path) for path in image_paths]\n",
    "\n",
    "# Preprocess images (assuming processor is defined elsewhere)\n",
    "inputs = processor(images=images, return_tensors='pt')\n",
    "pixel_values = inputs['pixel_values'].to(device)\n",
    "\n",
    "# Get image features (assuming model is defined elsewhere)\n",
    "with torch.no_grad():\n",
    "    image_features = model.get_image_features(pixel_values=pixel_values)\n",
    "\n",
    "# Normalize embeddings\n",
    "image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "embeddings = image_features.cpu().numpy()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "# Get unique classes and assign colors\n",
    "unique_classes = sorted(set(classes))\n",
    "# Combine tab20, tab20b, and tab20c for up to 60 distinct colors\n",
    "colors = (plt.cm.tab20(np.linspace(0, 1, 20))[:, :3].tolist() + \n",
    "          plt.cm.tab20b(np.linspace(0, 1, 20))[:, :3].tolist() + \n",
    "          plt.cm.tab20c(np.linspace(0, 1, 20))[:, :3].tolist())\n",
    "class_colors = {cls: colors[i % len(colors)] for i, cls in enumerate(unique_classes)}\n",
    "\n",
    "# Map each class to its set\n",
    "class_to_set = {cls: set_name for _, cls, set_name in all_image_data}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cls in unique_classes:\n",
    "    indices = [i for i, c in enumerate(classes) if c == cls]\n",
    "    x = embeddings_2d[indices, 0]\n",
    "    y = embeddings_2d[indices, 1]\n",
    "    color = class_colors[cls]\n",
    "    set_name = class_to_set[cls]\n",
    "    marker = markers[set_name]\n",
    "    plt.scatter(x, y, color=color, marker=marker, s=25)\n",
    "\n",
    "# Add legend for sets\n",
    "for set_name, marker in markers.items():\n",
    "    plt.scatter([], [], color='gray', marker=marker, label=set_name)\n",
    "plt.legend(title=\"Sets\")\n",
    "plt.title(\"PCA Visualization of CLIP Image Embeddings\\n(Colors represent classes)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot (assuming save_dir is defined elsewhere)\n",
    "image_pca_plot_path = os.path.join(save_dir, \"image_pca_clip_plot_all.png\")\n",
    "plt.savefig(image_pca_plot_path, bbox_inches=\"tight\", dpi=500)\n",
    "plt.close()\n",
    "print(f\"Image PCA plot saved to: {image_pca_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c179e-4a33-4a8f-90bc-aaedbf1f412c",
   "metadata": {},
   "source": [
    "# PCA plot, classes merged, legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d95d41-175a-412d-8bbf-bc8ab1a88019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Define base directory and set directories\n",
    "base_dir = \"/home/bboulbarss/large_dataset/relational\"\n",
    "sets = {\n",
    "    \"train\": os.path.join(base_dir, \"train\"),\n",
    "    \"val\": os.path.join(base_dir, \"ood_val\"),\n",
    "    \"test\": os.path.join(base_dir, \"ood_test\"),\n",
    "}\n",
    "\n",
    "# Define markers for each set\n",
    "markers = {\"train\": \"o\", \"val\": \"s\", \"test\": \"^\"}\n",
    "\n",
    "# Function to compute canonical class name\n",
    "def get_canonical_class(cls):\n",
    "    parts = cls.split('_')\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(f\"Invalid class name format: {cls}\")\n",
    "    shape1, relation, shape2 = parts\n",
    "    if relation not in ['left', 'right']:\n",
    "        raise ValueError(f\"Invalid relation in class name: {cls}\")\n",
    "    if shape1 < shape2:\n",
    "        return cls\n",
    "    else:\n",
    "        inverted_relation = 'right' if relation == 'left' else 'left'\n",
    "        return shape2 + '_' + inverted_relation + '_' + shape1\n",
    "\n",
    "# Function to get image paths based on set and directory structure\n",
    "def get_image_paths(set_name, set_dir):\n",
    "    image_data = []\n",
    "    # Get classes, ignoring dot files\n",
    "    classes = [c for c in os.listdir(set_dir) if not c.startswith('.')]\n",
    "    if set_name == \"train\":\n",
    "        for cls in classes:\n",
    "            canonical_cls = get_canonical_class(cls)\n",
    "            cls_dir = os.path.join(set_dir, cls)\n",
    "            # Get images, ignoring dot files\n",
    "            images = [img for img in os.listdir(cls_dir) if not img.startswith('.')]\n",
    "            for img in images:\n",
    "                path = os.path.join(cls_dir, img)\n",
    "                image_data.append((path, canonical_cls, set_name))\n",
    "    else:  # val or test\n",
    "        for cls in classes:\n",
    "            canonical_cls = get_canonical_class(cls)\n",
    "            cls_dir = os.path.join(set_dir, cls)\n",
    "            # Get the intermediate directory (assume there's only one, ignoring dot files)\n",
    "            intermediate_dirs = [d for d in os.listdir(cls_dir) if not d.startswith('.') and os.path.isdir(os.path.join(cls_dir, d))]\n",
    "            if intermediate_dirs:  # Ensure there's at least one intermediate directory\n",
    "                intermediate_dir = os.path.join(cls_dir, intermediate_dirs[0])\n",
    "                # Get images, ignoring dot files\n",
    "                images = [img for img in os.listdir(intermediate_dir) if not img.startswith('.')]\n",
    "                for img in images:\n",
    "                    path = os.path.join(intermediate_dir, img)\n",
    "                    image_data.append((path, canonical_cls, set_name))\n",
    "    return image_data\n",
    "\n",
    "# Collect all image data\n",
    "all_image_data = []\n",
    "for set_name, set_dir in sets.items():\n",
    "    image_data = get_image_paths(set_name, set_dir)\n",
    "    all_image_data.extend(image_data)\n",
    "\n",
    "# Extract image paths, canonical classes, and sets\n",
    "image_paths, classes, sets_list = zip(*all_image_data)\n",
    "\n",
    "# Load images\n",
    "images = [Image.open(path) for path in image_paths]\n",
    "\n",
    "# Preprocess images (assuming processor is defined elsewhere)\n",
    "inputs = processor(images=images, return_tensors='pt')\n",
    "pixel_values = inputs['pixel_values'].to(device)\n",
    "\n",
    "# Get image features (assuming model is defined elsewhere)\n",
    "with torch.no_grad():\n",
    "    image_features = model.get_image_features(pixel_values=pixel_values)\n",
    "\n",
    "# Normalize embeddings\n",
    "image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "embeddings = image_features.cpu().numpy()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "# Get unique canonical classes and assign colors\n",
    "unique_classes = sorted(set(classes))\n",
    "# Combine tab20, tab20b, and tab20c for up to 60 distinct colors\n",
    "colors = (plt.cm.tab20(np.linspace(0, 1, 20))[:, :3].tolist() + \n",
    "          plt.cm.tab20b(np.linspace(0, 1, 20))[:, :3].tolist() + \n",
    "          plt.cm.tab20c(np.linspace(0, 1, 20))[:, :3].tolist())\n",
    "class_colors = {cls: colors[i % len(colors)] for i, cls in enumerate(unique_classes)}\n",
    "\n",
    "# Map each canonical class to its set\n",
    "class_to_set = {cls: set_name for _, cls, set_name in all_image_data}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))  # Slightly larger figure to accommodate two legends\n",
    "for cls in unique_classes:\n",
    "    indices = [i for i, c in enumerate(classes) if c == cls]\n",
    "    x = embeddings_2d[indices, 0]\n",
    "    y = embeddings_2d[indices, 1]\n",
    "    color = class_colors[cls]\n",
    "    set_name = class_to_set[cls]\n",
    "    marker = markers[set_name]\n",
    "    plt.scatter(x, y, color=color, marker=marker, s=25)\n",
    "\n",
    "# Add legend for sets\n",
    "for set_name, marker in markers.items():\n",
    "    plt.scatter([], [], color='gray', marker=marker, label=set_name)\n",
    "set_legend = plt.legend(title=\"Sets\", loc='upper left', bbox_to_anchor=(1.02, 1.0))\n",
    "\n",
    "# Add legend for classes\n",
    "class_handles = [plt.scatter([], [], color=class_colors[cls], marker='o', label=cls) for cls in unique_classes]\n",
    "class_legend = plt.legend(handles=class_handles, title=\"Classes\", loc='upper left', bbox_to_anchor=(1.02, 0.7))\n",
    "\n",
    "# Add both legends to the plot\n",
    "plt.gca().add_artist(set_legend)\n",
    "plt.axis('equal')\n",
    "plt.title(\"PCA Visualization of CLIP Image Embeddings\\n(Colors: Classes, Markers: Sets)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "image_pca_plot_path = os.path.join(save_dir, \"image_pca_clip_plot_all.png\")\n",
    "plt.savefig(image_pca_plot_path, bbox_inches=\"tight\", dpi=500)\n",
    "plt.close()\n",
    "print(f\"Image PCA plot saved to: {image_pca_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f2cf6-1996-4619-9542-10bac0906f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
